{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc288f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Prevent OpenMP runtime conflicts (libomp vs libiomp) that crash the kernel\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# Keep thread counts modest to reduce chance of runtime contention on Windows\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2577812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= CONFIGURATION =================\n",
    "INPUT_FOLDER = 'data/images_shift'\n",
    "OUTPUT_FOLDER = 'output/shadow_masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27489e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLOv8 on 0...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-seg.pt to 'yolov8n-seg.pt': 100% ━━━━━━━━━━━━ 6.7MB 10.7MB/s 0.6s.6s<0.0s0s\n",
      "Generating Background Model...\n",
      "Processing 36 images...\n",
      "Saved: mask_IMG_20250906_110448_00_008.jpg\n",
      "Saved: mask_IMG_20250906_111350_00_016.jpg\n",
      "Saved: mask_IMG_20250906_112248_00_024.jpg\n",
      "Saved: mask_IMG_20250906_113147_00_032.jpg\n",
      "Saved: mask_IMG_20250906_114044_00_040.jpg\n",
      "Saved: mask_IMG_20250906_114942_00_048.jpg\n",
      "Saved: mask_IMG_20250906_115841_00_056.jpg\n",
      "Saved: mask_IMG_20250906_120744_00_064.jpg\n",
      "Saved: mask_IMG_20250906_121643_00_072.jpg\n",
      "Saved: mask_IMG_20250906_122542_00_080.jpg\n",
      "Saved: mask_IMG_20250906_123441_00_088.jpg\n",
      "Saved: mask_IMG_20250906_124340_00_096.jpg\n",
      "Saved: mask_IMG_20250906_125238_00_104.jpg\n",
      "Saved: mask_IMG_20250906_130139_00_112.jpg\n",
      "Saved: mask_IMG_20250906_131039_00_120.jpg\n",
      "Saved: mask_IMG_20250906_131937_00_128.jpg\n",
      "Saved: mask_IMG_20250906_132836_00_136.jpg\n",
      "Saved: mask_IMG_20250906_160131_00_143.jpg\n",
      "Saved: mask_IMG_20250906_161032_00_151.jpg\n",
      "Saved: mask_IMG_20250906_161930_00_159.jpg\n",
      "Saved: mask_IMG_20250906_162828_00_167.jpg\n",
      "Saved: mask_IMG_20250906_163726_00_175.jpg\n",
      "Saved: mask_IMG_20250906_164623_00_183.jpg\n",
      "Saved: mask_IMG_20250906_165520_00_191.jpg\n",
      "Saved: mask_IMG_20250906_170417_00_199.jpg\n",
      "Saved: mask_IMG_20250906_171318_00_207.jpg\n",
      "Saved: mask_IMG_20250906_172215_00_215.jpg\n",
      "Saved: mask_IMG_20250906_173112_00_223.jpg\n",
      "Saved: mask_IMG_20250906_174010_00_231.jpg\n",
      "Saved: mask_IMG_20250906_174907_00_239.jpg\n",
      "Saved: mask_IMG_20250906_175804_00_247.jpg\n",
      "Saved: mask_IMG_20250906_180701_00_255.jpg\n",
      "Saved: mask_IMG_20250906_181558_00_263.jpg\n",
      "Saved: mask_IMG_20250906_181558_00_263_preview.jpg\n",
      "Saved: mask_IMG_20250906_182456_00_271.jpg\n",
      "Saved: mask_IMG_20250906_183824_00_283.jpg\n",
      "Processing Complete.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. SHADOW SETTINGS\n",
    "RATIO_THRESHOLD = 0.65\n",
    "ABSOLUTE_DARK_THRESHOLD = 40\n",
    "\n",
    "# 2. PERSON HANDLING\n",
    "USE_AI = True\n",
    "AI_CONFIDENCE = 0.3\n",
    "CONTEXT_RING_SIZE = 20\n",
    "FILL_THRESHOLD = 0.5\n",
    "\n",
    "# 3. CLEANUP\n",
    "SKY_RATIO = 0.45\n",
    "MIN_SHADOW_SIZE = 200 # Minimum pixel area to keep\n",
    "# =================================================\n",
    "\n",
    "# Pre-calculate kernels to save time\n",
    "KERNEL_DILATE = np.ones((5,5), np.uint8)\n",
    "KERNEL_MORPH = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "KERNEL_RING = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (CONTEXT_RING_SIZE, CONTEXT_RING_SIZE))\n",
    "\n",
    "def create_background_model(files):\n",
    "    print(\"Generating Background Model...\")\n",
    "    first_img = cv2.imread(files[0])\n",
    "    max_buffer = np.zeros_like(first_img)\n",
    "\n",
    "    for f in files:\n",
    "        img = cv2.imread(f)\n",
    "        if img is None: continue\n",
    "        max_buffer = np.maximum(max_buffer, img)\n",
    "\n",
    "    return max_buffer\n",
    "\n",
    "def get_person_mask(img, model):\n",
    "    h, w = img.shape[:2]\n",
    "    person_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "    # Force GPU usage with device=0\n",
    "    results = model(img, classes=[0], verbose=False, conf=AI_CONFIDENCE, device=0)\n",
    "\n",
    "    if results[0].masks is not None:\n",
    "        masks = results[0].masks.data.cpu().numpy()\n",
    "        for mask in masks:\n",
    "            mask_resized = cv2.resize(mask, (w, h))\n",
    "            person_mask = np.maximum(person_mask, (mask_resized * 255).astype(np.uint8))\n",
    "\n",
    "    person_mask = cv2.dilate(person_mask, KERNEL_DILATE, iterations=1)\n",
    "    return person_mask\n",
    "\n",
    "def segment_shadows_raw(img, bg_model):\n",
    "    # Convert to float32 for faster vectorized division\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "    gray_bg = cv2.cvtColor(bg_model, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "\n",
    "    safe_bg = gray_bg.copy()\n",
    "    safe_bg[safe_bg == 0] = 1.0\n",
    "\n",
    "    # Vectorized operations\n",
    "    mask_ratio = (gray_img / safe_bg) < RATIO_THRESHOLD\n",
    "    mask_absolute = gray_img < ABSOLUTE_DARK_THRESHOLD\n",
    "\n",
    "    return np.logical_or(mask_ratio, mask_absolute).astype(np.uint8) * 255\n",
    "\n",
    "def fill_person_holes(shadow_mask, person_mask):\n",
    "    final_mask = shadow_mask.copy()\n",
    "\n",
    "    if person_mask is None or np.count_nonzero(person_mask) == 0:\n",
    "        return final_mask\n",
    "\n",
    "    contours, _ = cv2.findContours(person_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Loop is unavoidable here for context-aware logic, \n",
    "    # but efficient OpenCV calls minimize impact\n",
    "    for cnt in contours:\n",
    "        single_person_mask = np.zeros_like(shadow_mask)\n",
    "        cv2.drawContours(single_person_mask, [cnt], -1, 255, -1)\n",
    "\n",
    "        dilated_person = cv2.dilate(single_person_mask, KERNEL_RING)\n",
    "        ring_mask = cv2.subtract(dilated_person, single_person_mask)\n",
    "\n",
    "        shadow_pixels_in_ring = cv2.bitwise_and(ring_mask, shadow_mask)\n",
    "\n",
    "        total_ring_pixels = cv2.countNonZero(ring_mask)\n",
    "        if total_ring_pixels == 0: continue\n",
    "        \n",
    "        shadow_ring_pixels = cv2.countNonZero(shadow_pixels_in_ring)\n",
    "\n",
    "        if (shadow_ring_pixels / total_ring_pixels) > FILL_THRESHOLD:\n",
    "            final_mask = cv2.bitwise_or(final_mask, single_person_mask)\n",
    "        else:\n",
    "            final_mask = cv2.bitwise_and(final_mask, cv2.bitwise_not(single_person_mask))\n",
    "\n",
    "    return final_mask\n",
    "\n",
    "def post_process_fast(mask, h):\n",
    "    \"\"\"\n",
    "    Optimized cleanup using Vectorized NumPy operations.\n",
    "    \"\"\"\n",
    "    # 1. Mask Sky\n",
    "    sky_limit = int(h * SKY_RATIO)\n",
    "    mask[:sky_limit, :] = 0\n",
    "\n",
    "    # 2. Clean Noise\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, KERNEL_MORPH)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, KERNEL_MORPH)\n",
    "\n",
    "    # 3. Filter Small Regions (VECTORIZED - HIGH SPEED)\n",
    "    if MIN_SHADOW_SIZE > 0:\n",
    "        # Get components\n",
    "        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "\n",
    "        # stats[:, 4] is the Area column\n",
    "        sizes = stats[:, cv2.CC_STAT_AREA]\n",
    "\n",
    "        # Identify small blobs (True = remove, False = keep)\n",
    "        # We must make sure Background (index 0) is False, or we'll delete the canvas\n",
    "        small_blobs = sizes < MIN_SHADOW_SIZE\n",
    "        small_blobs[0] = False \n",
    "\n",
    "        # This line is the magic speedup.\n",
    "        # \"labels\" maps every pixel to an ID.\n",
    "        # \"small_blobs\" maps every ID to True/False.\n",
    "        # \"small_blobs[labels]\" generates a boolean mask for the whole image in one go.\n",
    "        mask[small_blobs[labels]] = 0\n",
    "\n",
    "    return mask\n",
    "\n",
    "# ================= MAIN LOOP =================\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(OUTPUT_FOLDER):\n",
    "        os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "    files = sorted(glob.glob(os.path.join(INPUT_FOLDER, \"*.jpg\")))\n",
    "    if not files:\n",
    "        print(\"No images found.\")\n",
    "        exit()\n",
    "\n",
    "    # 1. Load AI (Check for GPU)\n",
    "    model = None\n",
    "    if USE_AI:\n",
    "        device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Loading YOLOv8 on {device}...\")\n",
    "        model = YOLO('yolov8n-seg.pt')\n",
    "\n",
    "    # 2. Background Model\n",
    "    bg_model = create_background_model(files)\n",
    "    h, w = bg_model.shape[:2]\n",
    "    cv2.imwrite(os.path.join(OUTPUT_FOLDER, \"background_ref.jpg\"), bg_model)\n",
    "\n",
    "    print(f\"Processing {len(files)} images...\")\n",
    "\n",
    "    for f in files:\n",
    "        base_name = os.path.basename(f)\n",
    "        img = cv2.imread(f)\n",
    "\n",
    "        # A. Get Person Mask\n",
    "        p_mask = None\n",
    "        if USE_AI:\n",
    "            p_mask = get_person_mask(img, model)\n",
    "\n",
    "        # B. Get Raw Shadows\n",
    "        raw_shadows = segment_shadows_raw(img, bg_model)\n",
    "\n",
    "        # C. Remove People\n",
    "        if p_mask is not None:\n",
    "            shadows_no_people = cv2.bitwise_and(raw_shadows, cv2.bitwise_not(p_mask))\n",
    "        else:\n",
    "            shadows_no_people = raw_shadows\n",
    "\n",
    "        # D. Intelligent Fill\n",
    "        if p_mask is not None:\n",
    "            final_mask = fill_person_holes(shadows_no_people, p_mask)\n",
    "        else:\n",
    "            final_mask = shadows_no_people\n",
    "\n",
    "        # E. Fast Post Process\n",
    "        final_mask = post_process_fast(final_mask, h)\n",
    "\n",
    "        cv2.imwrite(os.path.join(OUTPUT_FOLDER, f\"mask_{base_name}\"), final_mask)\n",
    "        print(f\"Saved: mask_{base_name}\")\n",
    "\n",
    "    print(\"Processing Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2050c918",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'INPUT_FOLDER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m         plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Run the display\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m display_results(\u001b[43mINPUT_FOLDER\u001b[49m, OUTPUT_FOLDER, limit\u001b[38;5;241m=\u001b[39mNUM_SAMPLES, resize_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'INPUT_FOLDER' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "# INPUT_FOLDER = 'images'     # Folder with original images\n",
    "# OUTPUT_FOLDER = 'output_masks_people'    # Folder with generated masks\n",
    "NUM_SAMPLES = 36                   # How many pairs to display\n",
    "# =================================================\n",
    "\n",
    "def display_results(input_dir, output_dir, limit=5, resize_factor=1.0):\n",
    "    # Get list of original images\n",
    "    input_files = sorted(glob.glob(os.path.join(input_dir, \"*\")))\n",
    "\n",
    "    # Filter for image extensions only\n",
    "    input_files = [f for f in input_files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    if not input_files:\n",
    "        print(\"No images found to display.\")\n",
    "        return\n",
    "\n",
    "    # Loop through the desired number of samples\n",
    "    for i, file_path in enumerate(input_files[:limit]):\n",
    "        filename = os.path.basename(file_path)\n",
    "\n",
    "        # Construct path to corresponding mask\n",
    "        # (Assuming the naming convention from previous script: 'mask_filename')\n",
    "        mask_path = os.path.join(output_dir, f\"mask_{filename}\")\n",
    "\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Mask not found for: {filename}\")\n",
    "            continue\n",
    "\n",
    "        # Load images\n",
    "        # 1. Original: Read as BGR, Convert to RGB for Matplotlib\n",
    "        original = cv2.imread(file_path)\n",
    "        original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 2. Mask: Read as Grayscale\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Resize images if resize_factor is less than 1.0\n",
    "        if resize_factor < 1.0:\n",
    "            h, w = original.shape[:2]\n",
    "            original = cv2.resize(original, (int(w * resize_factor), int(h * resize_factor)), interpolation=cv2.INTER_AREA)\n",
    "            mask = cv2.resize(mask, (int(w * resize_factor), int(h * resize_factor)), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Plotting\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(20, 5)) # Wide layout for 360 images\n",
    "\n",
    "        # Original Image\n",
    "        axes[0].imshow(original)\n",
    "        axes[0].set_title(f\"Original: {filename}\")\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # Generated Mask\n",
    "        axes[1].imshow(mask, cmap='gray')\n",
    "        axes[1].set_title(\"Generated Shadow Mask\")\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Run the display\n",
    "display_results(INPUT_FOLDER, OUTPUT_FOLDER, limit=NUM_SAMPLES, resize_factor=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panogeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
