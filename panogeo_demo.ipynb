{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export H3-aggregated PNGs grouped by date and by hour of day\n",
        "from pathlib import Path\n",
        "import re\n",
        "import pandas as pd\n",
        "import h3\n",
        "from panogeo.mapplot import save_h3_basemap, merc_extent_from_center\n",
        "\n",
        "# Config (kept consistent with previous cells)\n",
        "OUTPUT_DIR = \"./output\"\n",
        "PROVIDER = \"japan_gsi_air\"  # \"carto\", \"osm\", \"esri-world\", \"japan_gsi_seamless\", \"japan_gsi_air\", or XYZ URL\n",
        "WIDTH_M = 150.0\n",
        "HEIGHT_M = 150.0\n",
        "H3_RES = 14\n",
        "CAM_LAT = 35.16928165\n",
        "CAM_LON = 136.90860244\n",
        "\n",
        "# Optional fixed color scales per series (set *_VMAX=None to auto-compute)\n",
        "DATE_VMIN, DATE_VMAX = 0, None\n",
        "HOUR_VMIN, HOUR_VMAX = 0, None\n",
        "\n",
        "# Fixed extent for visual consistency across all exports\n",
        "fixed_extent = merc_extent_from_center(center_lat=CAM_LAT, center_lon=CAM_LON, width_m=WIDTH_M, height_m=HEIGHT_M)\n",
        "\n",
        "# Load detections with lat/lon\n",
        "geo_csv = str(Path(OUTPUT_DIR) / \"all_people_geo_calibrated.csv\")\n",
        "df = pd.read_csv(geo_csv)\n",
        "if df.empty:\n",
        "    raise ValueError(\"No rows in geo CSV\")\n",
        "if not {\"lat\", \"lon\"}.issubset(df.columns):\n",
        "    raise ValueError(\"CSV must contain 'lat' and 'lon' columns\")\n",
        "\n",
        "# Exclude detections within 2 m buffer of the camera position and report excluded count\n",
        "BUFFER_M = 2.0\n",
        "n_before = int(len(df))\n",
        "if \"range_m\" in df.columns:\n",
        "    _mask = df[\"range_m\"].astype(float) > BUFFER_M\n",
        "elif {\"east_m\", \"north_m\"}.issubset(df.columns):\n",
        "    _rng = (df[\"east_m\"].astype(float) ** 2 + df[\"north_m\"].astype(float) ** 2) ** 0.5\n",
        "    _mask = _rng > BUFFER_M\n",
        "else:\n",
        "    import numpy as np\n",
        "    lat1 = np.radians(CAM_LAT)\n",
        "    lon1 = np.radians(CAM_LON)\n",
        "    lat2 = np.radians(df[\"lat\"].astype(float).to_numpy())\n",
        "    lon2 = np.radians(df[\"lon\"].astype(float).to_numpy())\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
        "    c = 2.0 * np.arctan2(np.sqrt(a), np.sqrt(1.0 - a))\n",
        "    R = 6371000.0  # meters\n",
        "    dist = R * c\n",
        "    _mask = dist > BUFFER_M\n",
        "\n",
        "excluded_count = int((~_mask).sum())\n",
        "df = df[_mask].reset_index(drop=True)\n",
        "print(f\"Excluded by {BUFFER_M:.1f} m buffer: {excluded_count} of {n_before} total\")\n",
        "\n",
        "# Parse timestamp from image names like IMG_YYYYMMDD_HHMMSS_**_**.jpg → date, hour\n",
        "_ts_re = re.compile(r\"IMG_(\\d{8})_(\\d{6})_\")\n",
        "\n",
        "def _parse_date_hour(name: str):\n",
        "    m = _ts_re.search(str(name))\n",
        "    if not m:\n",
        "        return None, None\n",
        "    ymd, hms = m.groups()\n",
        "    date = f\"{ymd[:4]}-{ymd[4:6]}-{ymd[6:]}\"\n",
        "    hour = hms[:2]\n",
        "    return date, hour\n",
        "\n",
        "# Expand into two columns with apply (not map)\n",
        "tmp = df[\"image\"].apply(lambda x: pd.Series(_parse_date_hour(x), index=[\"date\", \"hour\"]))\n",
        "df[[\"date\", \"hour\"]] = tmp\n",
        "df = df.dropna(subset=[\"date\", \"hour\"]).reset_index(drop=True)\n",
        "\n",
        "# Output folders\n",
        "out_date_dir = Path(OUTPUT_DIR) / \"h3_by_date\"\n",
        "out_hour_dir = Path(OUTPUT_DIR) / \"h3_by_hour\"\n",
        "out_date_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_hour_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Temporary CSV reused for each group\n",
        "_tmp_csv = Path(OUTPUT_DIR) / \"_tmp_h3_group.csv\"\n",
        "\n",
        "# Helper to save a group's H3 map\n",
        "def _save_group(sub_df: pd.DataFrame, out_png: Path, vmin=None, vmax=None):\n",
        "    if sub_df.empty:\n",
        "        return None\n",
        "    # Write only needed columns; keep extras if present\n",
        "    sub_df.to_csv(_tmp_csv, index=False)\n",
        "    return save_h3_basemap(\n",
        "        geo_csv=str(_tmp_csv),\n",
        "        out_png=str(out_png),\n",
        "        provider=PROVIDER,\n",
        "        zoom=18,\n",
        "        h3_res=H3_RES,\n",
        "        weight_col=None,  # or 'conf' to sum confidences\n",
        "        alpha=0.5,\n",
        "        dpi=150,\n",
        "        margin_frac=0.10,\n",
        "        fixed_extent_merc=fixed_extent,\n",
        "        cmap=\"viridis\",\n",
        "        edgecolor=\"#00000000\",  # transparent edges to avoid moiré/hatching\n",
        "        linewidth=0.0,\n",
        "        vmin=vmin,\n",
        "        vmax=vmax,\n",
        "        add_colorbar=True,\n",
        "        colorbar_label=\"count\" if (\"conf\" not in sub_df.columns) else \"conf sum\",\n",
        "        rasterized=True,\n",
        "    )\n",
        "\n",
        "# Compute global vmax across all dates for consistent scale\n",
        "unique_dates = sorted(df[\"date\"].unique())\n",
        "unique_hours = sorted(df[\"hour\"].unique())\n",
        "\n",
        "def _series_global_max(groups, keyname: str):\n",
        "    if keyname == \"date\":\n",
        "        keys = groups\n",
        "    else:\n",
        "        keys = groups\n",
        "    global_max = 0.0\n",
        "    for key in keys:\n",
        "        sub = df[df[keyname] == key]\n",
        "        if sub.empty:\n",
        "            continue\n",
        "        # Aggregate to H3 and get max value\n",
        "        lat = sub[\"lat\"].astype(float).to_numpy()\n",
        "        lon = sub[\"lon\"].astype(float).to_numpy()\n",
        "        if hasattr(h3, \"latlng_to_cell\"):\n",
        "            cells = [h3.latlng_to_cell(float(la), float(lo), int(H3_RES)) for la, lo in zip(lat, lon)]\n",
        "        else:\n",
        "            cells = [h3.geo_to_h3(float(la), float(lo), int(H3_RES)) for la, lo in zip(lat, lon)]\n",
        "        tmp = pd.DataFrame({\"h3\": cells})\n",
        "        agg = tmp.groupby(\"h3\").size()\n",
        "        if not agg.empty:\n",
        "            m = float(agg.max())\n",
        "            if m > global_max:\n",
        "                global_max = m\n",
        "    return global_max\n",
        "\n",
        "_date_vmax = float(DATE_VMAX) if DATE_VMAX is not None else _series_global_max(unique_dates, \"date\")\n",
        "_hour_vmax = float(HOUR_VMAX) if HOUR_VMAX is not None else _series_global_max(unique_hours, \"hour\")\n",
        "\n",
        "# 1) Save per-date H3 maps\n",
        "for date in unique_dates:\n",
        "    sub = df[df[\"date\"] == date]\n",
        "    out_png = out_date_dir / f\"people_summary_h3_r{H3_RES}_{date}_{PROVIDER}.png\"\n",
        "    try:\n",
        "        out = _save_group(sub, out_png, vmin=DATE_VMIN, vmax=_date_vmax)\n",
        "        if out:\n",
        "            print(f\"Saved: {out}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving date {date}: {e}\")\n",
        "\n",
        "# 2) Save per-hour-of-day H3 maps (across all dates)\n",
        "for hour in unique_hours:\n",
        "    sub = df[df[\"hour\"] == hour]\n",
        "    out_png = out_hour_dir / f\"people_summary_h3_r{H3_RES}_hour-{hour}_{PROVIDER}.png\"\n",
        "    try:\n",
        "        out = _save_group(sub, out_png, vmin=HOUR_VMIN, vmax=_hour_vmax)\n",
        "        if out:\n",
        "            print(f\"Saved: {out}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving hour {hour}: {e}\")\n",
        "\n",
        "# Cleanup temp CSV (best-effort)\n",
        "try:\n",
        "    if _tmp_csv.exists():\n",
        "        _tmp_csv.unlink()\n",
        "except Exception:\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Prevent OpenMP runtime conflict in Windows (libiomp5md.dll vs libomp.dll)\n",
        "import os\n",
        "os.environ.setdefault(\"KMP_DUPLICATE_LIB_OK\", \"TRUE\")\n",
        "# Optional: reduce oversubscription\n",
        "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# panogeo demo\n",
        "\n",
        "End-to-end demo of detection and geolocation from panoramic imagery.\n",
        "\n",
        "Requirements:\n",
        "- Install environment: `conda env create -f environment.yml && conda activate panogeo`\n",
        "- Install package: `pip install -e .`\n",
        "- Prepare a folder of panoramas (equirectangular 2:1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive calibration UI demo\n",
        "from panogeo import launch_calibration_ui\n",
        "\n",
        "# Choose a pano image and a sensible map center (lat, lon)\n",
        "ui = launch_calibration_ui(\n",
        "    pano_path=\"data/images_shift/IMG_20250906_181558_00_263.jpg\",\n",
        "    map_center=(35.169237383755025, 136.90874779113642),  # TODO: set to your camera area\n",
        "    map_zoom=19,\n",
        "    display_width_px=1800,\n",
        "    default_alt_m=0.0,\n",
        ")\n",
        "ui.display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete.\n"
          ]
        }
      ],
      "source": [
        "# Imports & paths\n",
        "from pathlib import Path\n",
        "from IPython.display import display\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from panogeo.cli import main as panogeo_cli\n",
        "\n",
        "# Set your paths\n",
        "IMAGES_DIR = \"./data/images\"           # input panoramas\n",
        "SHIFT_DIR  = \"./data/images_shift\"     # shifted output\n",
        "OUTPUT_DIR = \"./output\"                # outputs\n",
        "CALIB_CSV  = f\"{OUTPUT_DIR}/calib_points.csv\"  # provide or capture via your own tool\n",
        "\n",
        "Path(SHIFT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Setup complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 36 image(s) to ./data/images_shift\n"
          ]
        }
      ],
      "source": [
        "# 1) Optional: yaw-shift panoramas so forward faces North (or desired yaw)\n",
        "panogeo_cli([\"shift-pano\", \"--in-dir\", IMAGES_DIR, \"--out-dir\", SHIFT_DIR, \"--degrees\", \"200\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLOv8s summary (fused): 72 layers, 11,156,544 parameters, 0 gradients, 28.6 GFLOPs\n",
            "Detections saved: ./output\\detections\\detections_all.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>input_path</th>\n",
              "      <th>W</th>\n",
              "      <th>H</th>\n",
              "      <th>bbox_x1</th>\n",
              "      <th>bbox_y1</th>\n",
              "      <th>bbox_x2</th>\n",
              "      <th>bbox_y2</th>\n",
              "      <th>u_px</th>\n",
              "      <th>v_px</th>\n",
              "      <th>conf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IMG_20250906_110448_00_008</td>\n",
              "      <td>./data/images_shift\\IMG_20250906_110448_00_008...</td>\n",
              "      <td>11904</td>\n",
              "      <td>5952</td>\n",
              "      <td>5119.000</td>\n",
              "      <td>3133.75</td>\n",
              "      <td>5231.0</td>\n",
              "      <td>3322.0</td>\n",
              "      <td>5175.0000</td>\n",
              "      <td>3322.0</td>\n",
              "      <td>0.886719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IMG_20250906_110448_00_008</td>\n",
              "      <td>./data/images_shift\\IMG_20250906_110448_00_008...</td>\n",
              "      <td>11904</td>\n",
              "      <td>5952</td>\n",
              "      <td>2915.375</td>\n",
              "      <td>3134.50</td>\n",
              "      <td>3010.5</td>\n",
              "      <td>3282.5</td>\n",
              "      <td>2962.9375</td>\n",
              "      <td>3282.5</td>\n",
              "      <td>0.829102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IMG_20250906_110448_00_008</td>\n",
              "      <td>./data/images_shift\\IMG_20250906_110448_00_008...</td>\n",
              "      <td>11904</td>\n",
              "      <td>5952</td>\n",
              "      <td>5253.000</td>\n",
              "      <td>3024.50</td>\n",
              "      <td>5292.0</td>\n",
              "      <td>3093.0</td>\n",
              "      <td>5272.5000</td>\n",
              "      <td>3093.0</td>\n",
              "      <td>0.819824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IMG_20250906_110448_00_008</td>\n",
              "      <td>./data/images_shift\\IMG_20250906_110448_00_008...</td>\n",
              "      <td>11904</td>\n",
              "      <td>5952</td>\n",
              "      <td>3736.000</td>\n",
              "      <td>3098.00</td>\n",
              "      <td>3824.0</td>\n",
              "      <td>3308.0</td>\n",
              "      <td>3780.0000</td>\n",
              "      <td>3308.0</td>\n",
              "      <td>0.790527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IMG_20250906_110448_00_008</td>\n",
              "      <td>./data/images_shift\\IMG_20250906_110448_00_008...</td>\n",
              "      <td>11904</td>\n",
              "      <td>5952</td>\n",
              "      <td>2482.000</td>\n",
              "      <td>4160.00</td>\n",
              "      <td>2819.0</td>\n",
              "      <td>4320.0</td>\n",
              "      <td>2650.5000</td>\n",
              "      <td>4320.0</td>\n",
              "      <td>0.787109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        image  \\\n",
              "0  IMG_20250906_110448_00_008   \n",
              "1  IMG_20250906_110448_00_008   \n",
              "2  IMG_20250906_110448_00_008   \n",
              "3  IMG_20250906_110448_00_008   \n",
              "4  IMG_20250906_110448_00_008   \n",
              "\n",
              "                                          input_path      W     H   bbox_x1  \\\n",
              "0  ./data/images_shift\\IMG_20250906_110448_00_008...  11904  5952  5119.000   \n",
              "1  ./data/images_shift\\IMG_20250906_110448_00_008...  11904  5952  2915.375   \n",
              "2  ./data/images_shift\\IMG_20250906_110448_00_008...  11904  5952  5253.000   \n",
              "3  ./data/images_shift\\IMG_20250906_110448_00_008...  11904  5952  3736.000   \n",
              "4  ./data/images_shift\\IMG_20250906_110448_00_008...  11904  5952  2482.000   \n",
              "\n",
              "   bbox_y1  bbox_x2  bbox_y2       u_px    v_px      conf  \n",
              "0  3133.75   5231.0   3322.0  5175.0000  3322.0  0.886719  \n",
              "1  3134.50   3010.5   3282.5  2962.9375  3282.5  0.829102  \n",
              "2  3024.50   5292.0   3093.0  5272.5000  3093.0  0.819824  \n",
              "3  3098.00   3824.0   3308.0  3780.0000  3308.0  0.790527  \n",
              "4  4160.00   2819.0   4320.0  2650.5000  4320.0  0.787109  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 2) Detect people in panoramas with tiling\n",
        "panogeo_cli([\n",
        "    \"detect\",\n",
        "    \"--images-dir\", SHIFT_DIR,\n",
        "    \"--output-dir\", OUTPUT_DIR,\n",
        "    \"--model\", \"yolov8s.pt\",\n",
        "    \"--conf\", \"0.50\",\n",
        "    \"--iou\", \"0.50\",\n",
        "    \"--containment-thr\", \"0.50\",\n",
        "    \"--annotate\",\n",
        "    \"--stamp\",\n",
        "    \"--annotate-dir\", OUTPUT_DIR + \"/annotated\",\n",
        "    \"--device\", \"cuda:0\",\n",
        "    \"--batch-tiles\", \"16\",\n",
        "    \"--fuse-model\",\n",
        "    \"--half\",\n",
        "    \"--bbox-color\", \"#FF00FF\",\n",
        "    # omit --half to keep outputs identical; add it later for extra speed\n",
        "])\n",
        "\n",
        "# Inspect aggregate detections\n",
        "agg_csv = f\"{OUTPUT_DIR}/detections/detections_all.csv\"\n",
        "df_det = pd.read_csv(agg_csv)\n",
        "display(df_det.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "agg_csv = f\"{OUTPUT_DIR}/detections/detections_all.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved calibration to: ./output\\calibration_cam2enu.npz\n",
            "yaw=-3.27°, pitch=-0.89°, roll=0.08°\n",
            "CAM_LAT=35.16928165, CAM_LON=136.90860244, CAMERA_ALT_M=2.34\n"
          ]
        }
      ],
      "source": [
        "# 3) Calibrate camera rotation from pixel↔geo pairs\n",
        "\n",
        "from panogeo.cli import main as panogeo_cli\n",
        "\n",
        "# Provide a CSV with columns: image,u_px,v_px,lon,lat[,alt_m][,W,H]\n",
        "# Set your known camera location and altitude\n",
        "CAM_LAT       = 35.16928165\n",
        "CAM_LON       = 136.90860244\n",
        "CAMERA_ALT_M  = 2.34       # camera altitude above local ground mean sea level (approx). Used only to set camera Z in ENU.\n",
        "GROUND_ALT_M  = 0.0       # assumed ground altitude (MSL) when calib alt is absent\n",
        "\n",
        "panogeo_cli([\n",
        "    \"calibrate\",\n",
        "    \"--calib-csv\", CALIB_CSV,\n",
        "    \"--cam-lat\", str(CAM_LAT),\n",
        "    \"--cam-lon\", str(CAM_LON),\n",
        "    \"--camera-alt-m\", str(CAMERA_ALT_M),\n",
        "    \"--ground-alt-m\", str(GROUND_ALT_M),\n",
        "    \"--output-dir\", OUTPUT_DIR,\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: ./output\\all_people_xy_calibrated.csv\n",
            "Saved: ./output\\all_people_geo_calibrated.csv\n",
            "Rows: 1068\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>input_path</th>\n",
              "      <th>W</th>\n",
              "      <th>H</th>\n",
              "      <th>bbox_x1</th>\n",
              "      <th>bbox_y1</th>\n",
              "      <th>bbox_x2</th>\n",
              "      <th>bbox_y2</th>\n",
              "      <th>u_px</th>\n",
              "      <th>v_px</th>\n",
              "      <th>conf</th>\n",
              "      <th>east_m</th>\n",
              "      <th>north_m</th>\n",
              "      <th>up_m</th>\n",
              "      <th>lon</th>\n",
              "      <th>lat</th>\n",
              "      <th>range_m</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IMG_20250906_110448_00_008</td>\n",
              "      <td>./data/images_shift\\IMG_20250906_110448_00_008...</td>\n",
              "      <td>11904</td>\n",
              "      <td>5952</td>\n",
              "      <td>5118.838379</td>\n",
              "      <td>3133.548340</td>\n",
              "      <td>5230.365723</td>\n",
              "      <td>3321.864746</td>\n",
              "      <td>5174.602051</td>\n",
              "      <td>3321.864746</td>\n",
              "      <td>0.886842</td>\n",
              "      <td>-5.317374</td>\n",
              "      <td>10.497041</td>\n",
              "      <td>-2.34</td>\n",
              "      <td>136.908544</td>\n",
              "      <td>35.169376</td>\n",
              "      <td>11.997414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IMG_20250906_110448_00_008</td>\n",
              "      <td>./data/images_shift\\IMG_20250906_110448_00_008...</td>\n",
              "      <td>11904</td>\n",
              "      <td>5952</td>\n",
              "      <td>2915.221191</td>\n",
              "      <td>3134.777588</td>\n",
              "      <td>3010.486084</td>\n",
              "      <td>3282.276855</td>\n",
              "      <td>2962.853638</td>\n",
              "      <td>3282.276855</td>\n",
              "      <td>0.828276</td>\n",
              "      <td>-14.453090</td>\n",
              "      <td>-0.963805</td>\n",
              "      <td>-2.34</td>\n",
              "      <td>136.908444</td>\n",
              "      <td>35.169273</td>\n",
              "      <td>14.672980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IMG_20250906_110448_00_008</td>\n",
              "      <td>./data/images_shift\\IMG_20250906_110448_00_008...</td>\n",
              "      <td>11904</td>\n",
              "      <td>5952</td>\n",
              "      <td>5252.989258</td>\n",
              "      <td>3024.639160</td>\n",
              "      <td>5291.881836</td>\n",
              "      <td>3092.975098</td>\n",
              "      <td>5272.435547</td>\n",
              "      <td>3092.975098</td>\n",
              "      <td>0.819814</td>\n",
              "      <td>-12.449098</td>\n",
              "      <td>28.158383</td>\n",
              "      <td>-2.34</td>\n",
              "      <td>136.908466</td>\n",
              "      <td>35.169535</td>\n",
              "      <td>30.876369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IMG_20250906_110448_00_008</td>\n",
              "      <td>./data/images_shift\\IMG_20250906_110448_00_008...</td>\n",
              "      <td>11904</td>\n",
              "      <td>5952</td>\n",
              "      <td>3735.639404</td>\n",
              "      <td>3098.066895</td>\n",
              "      <td>3824.963623</td>\n",
              "      <td>3307.867432</td>\n",
              "      <td>3780.301514</td>\n",
              "      <td>3307.867432</td>\n",
              "      <td>0.790180</td>\n",
              "      <td>-11.991505</td>\n",
              "      <td>4.578837</td>\n",
              "      <td>-2.34</td>\n",
              "      <td>136.908471</td>\n",
              "      <td>35.169323</td>\n",
              "      <td>13.047511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IMG_20250906_110448_00_008</td>\n",
              "      <td>./data/images_shift\\IMG_20250906_110448_00_008...</td>\n",
              "      <td>11904</td>\n",
              "      <td>5952</td>\n",
              "      <td>2481.884766</td>\n",
              "      <td>4159.875488</td>\n",
              "      <td>2819.316162</td>\n",
              "      <td>4319.469727</td>\n",
              "      <td>2650.600464</td>\n",
              "      <td>4319.469727</td>\n",
              "      <td>0.786164</td>\n",
              "      <td>-2.670138</td>\n",
              "      <td>-0.658454</td>\n",
              "      <td>-2.34</td>\n",
              "      <td>136.908573</td>\n",
              "      <td>35.169276</td>\n",
              "      <td>3.610928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        image  \\\n",
              "0  IMG_20250906_110448_00_008   \n",
              "1  IMG_20250906_110448_00_008   \n",
              "2  IMG_20250906_110448_00_008   \n",
              "3  IMG_20250906_110448_00_008   \n",
              "4  IMG_20250906_110448_00_008   \n",
              "\n",
              "                                          input_path      W     H  \\\n",
              "0  ./data/images_shift\\IMG_20250906_110448_00_008...  11904  5952   \n",
              "1  ./data/images_shift\\IMG_20250906_110448_00_008...  11904  5952   \n",
              "2  ./data/images_shift\\IMG_20250906_110448_00_008...  11904  5952   \n",
              "3  ./data/images_shift\\IMG_20250906_110448_00_008...  11904  5952   \n",
              "4  ./data/images_shift\\IMG_20250906_110448_00_008...  11904  5952   \n",
              "\n",
              "       bbox_x1      bbox_y1      bbox_x2      bbox_y2         u_px  \\\n",
              "0  5118.838379  3133.548340  5230.365723  3321.864746  5174.602051   \n",
              "1  2915.221191  3134.777588  3010.486084  3282.276855  2962.853638   \n",
              "2  5252.989258  3024.639160  5291.881836  3092.975098  5272.435547   \n",
              "3  3735.639404  3098.066895  3824.963623  3307.867432  3780.301514   \n",
              "4  2481.884766  4159.875488  2819.316162  4319.469727  2650.600464   \n",
              "\n",
              "          v_px      conf     east_m    north_m  up_m         lon        lat  \\\n",
              "0  3321.864746  0.886842  -5.317374  10.497041 -2.34  136.908544  35.169376   \n",
              "1  3282.276855  0.828276 -14.453090  -0.963805 -2.34  136.908444  35.169273   \n",
              "2  3092.975098  0.819814 -12.449098  28.158383 -2.34  136.908466  35.169535   \n",
              "3  3307.867432  0.790180 -11.991505   4.578837 -2.34  136.908471  35.169323   \n",
              "4  4319.469727  0.786164  -2.670138  -0.658454 -2.34  136.908573  35.169276   \n",
              "\n",
              "     range_m  \n",
              "0  11.997414  \n",
              "1  14.672980  \n",
              "2  30.876369  \n",
              "3  13.047511  \n",
              "4   3.610928  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 4) Geolocate detections to ENU and WGS84\n",
        "calib_npz = f\"{OUTPUT_DIR}/calibration_cam2enu.npz\"\n",
        "panogeo_cli([\n",
        "    \"geolocate\",\n",
        "    \"--detections-csv\", agg_csv,\n",
        "    \"--calibration\", calib_npz,\n",
        "    \"--output-dir\", OUTPUT_DIR,\n",
        "])\n",
        "\n",
        "geo_csv = f\"{OUTPUT_DIR}/all_people_geo_calibrated.csv\"\n",
        "df_geo = pd.read_csv(geo_csv)\n",
        "print(f\"Rows: {len(df_geo)}\")\n",
        "display(df_geo.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7) Folium all points (no aggregation)\n",
        "try:\n",
        "    import folium\n",
        "\n",
        "    m_points_all = folium.Map(location=[float(df_geo[\"lat\"].mean()), float(df_geo[\"lon\"].mean())], zoom_start=19, tiles=None)\n",
        "    # Google Satellite tiles\n",
        "    folium.TileLayer(\n",
        "        tiles=\"https://{s}.google.com/vt/lyrs=s&x={x}&y={y}&z={z}\",\n",
        "        attr=\"© Google\",\n",
        "        name=\"Google Satellite\",\n",
        "        subdomains=[\"mt0\",\"mt1\",\"mt2\",\"mt3\"],\n",
        "        max_zoom=21,\n",
        "    ).add_to(m_points_all)\n",
        "\n",
        "    for r in df_geo.itertuples():\n",
        "        conf = float(getattr(r, \"conf\", 1.0))\n",
        "        folium.CircleMarker(\n",
        "            location=[float(r.lat), float(r.lon)],\n",
        "            radius=0.2,\n",
        "            color=\"#2196f3\",\n",
        "            fill=True,\n",
        "            fill_color=\"#2196f3\",\n",
        "            fill_opacity=0.6,\n",
        "            popup=f\"{r.image} (conf={conf:.2f})\",\n",
        "        ).add_to(m_points_all)\n",
        "except Exception as e:\n",
        "    print(\"Folium not available or error building all-points map:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(m_points_all)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 36 images to output\\maps_all\n"
          ]
        }
      ],
      "source": [
        "# 6b) Export PNG basemaps for all images with a fixed 100m x 100m basemap centered at camera\n",
        "from pathlib import Path\n",
        "from panogeo.mapplot import save_all_images_basemap, merc_extent_from_center\n",
        "\n",
        "OUTPUT_DIR = \"./output\"                # outputs\n",
        "CAM_LAT       = 35.16928165\n",
        "CAM_LON       = 136.90860244\n",
        "\n",
        "maps_dir = Path(OUTPUT_DIR) / \"maps_all\"\n",
        "maps_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "PROVIDER = \"japan_gsi_air\"  # \"carto\", \"osm\", \"esri-world\" (Esri imagery), \"japan_gsi\", or XYZ URL\n",
        "\n",
        "# Use CAM_LAT/CAM_LON set earlier in the notebook\n",
        "WIDTH_M = 100.0\n",
        "HEIGHT_M = 100.0\n",
        "\n",
        "try:\n",
        "    fixed_extent = merc_extent_from_center(center_lat=CAM_LAT, center_lon=CAM_LON, width_m=WIDTH_M, height_m=HEIGHT_M)\n",
        "    saved = save_all_images_basemap(\n",
        "        geo_csv=f\"{OUTPUT_DIR}/all_people_geo_calibrated.csv\",\n",
        "        out_dir=str(maps_dir),\n",
        "        provider=PROVIDER,\n",
        "        zoom=18,  # or None to auto-select\n",
        "        point_size=15.0,\n",
        "        alpha=0.9,\n",
        "        point_color=\"#FF00FF\",\n",
        "        dpi=150,\n",
        "        margin_frac=0.10,\n",
        "        fixed_extent_merc=fixed_extent,\n",
        "        # stamp_timestamp=True,   # toggle here\n",
        "    )\n",
        "    print(f\"Saved {len(saved)} images to {maps_dir}\")\n",
        "except Exception as e:\n",
        "    print(\"PNG basemap export requires geopandas/contextily.\")\n",
        "    print(\"Install extras: pip install 'panogeo[geo]'\")\n",
        "    print(\"Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: output\\people_summary_carto.png\n"
          ]
        }
      ],
      "source": [
        "# 6c) Export a single PNG summary map of all detections (fixed 100m x 100m)\n",
        "from pathlib import Path\n",
        "from panogeo.mapplot import save_points_basemap, merc_extent_from_center\n",
        "\n",
        "PROVIDER = \"carto\"  # \"carto\", \"osm\", \"esri-world\" (Esri imagery), \"japan_gsi\", or XYZ URL\n",
        "WIDTH_M = 100.0\n",
        "HEIGHT_M = 100.0\n",
        "\n",
        "summary_png = Path(OUTPUT_DIR) / f\"people_summary_{PROVIDER}.png\"\n",
        "\n",
        "try:\n",
        "    fixed_extent = merc_extent_from_center(center_lat=CAM_LAT, center_lon=CAM_LON, width_m=WIDTH_M, height_m=HEIGHT_M)\n",
        "    out = save_points_basemap(\n",
        "        geo_csv=f\"{OUTPUT_DIR}/all_people_geo_calibrated.csv\",\n",
        "        out_png=str(summary_png),\n",
        "        provider=PROVIDER,\n",
        "        zoom=19,  # or None to auto-select\n",
        "        point_size=16.0,\n",
        "        alpha=0.9,\n",
        "        dpi=150,\n",
        "        margin_frac=0.10,\n",
        "        image_name=None,\n",
        "        fixed_extent_merc=fixed_extent,\n",
        "    )\n",
        "    print(f\"Saved: {out}\")\n",
        "except Exception as e:\n",
        "    print(\"PNG basemap export requires geopandas/contextily.\")\n",
        "    print(\"Install extras: pip install 'panogeo[geo]'\")\n",
        "    print(\"Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: output\\people_summary_h3_r14_carto.png\n"
          ]
        }
      ],
      "source": [
        "# 6d) Export an H3-aggregated PNG summary map of all detections\n",
        "from pathlib import Path\n",
        "from panogeo.mapplot import save_h3_basemap, merc_extent_from_center\n",
        "\n",
        "OUTPUT_DIR = \"./output\"                # outputs\n",
        "CAM_LAT       = 35.16928165\n",
        "CAM_LON       = 136.90860244\n",
        "\n",
        "PROVIDER = \"carto\"  # \"carto\", \"osm\", \"esri-world\" (Esri imagery), \"japan_gsi\", or XYZ URL\n",
        "WIDTH_M = 150.0\n",
        "HEIGHT_M = 150.0\n",
        "H3_RES = 14   # smaller number = larger hexagons (e.g., 8..11)\n",
        "\n",
        "h3_png = Path(OUTPUT_DIR) / f\"people_summary_h3_r{H3_RES}_{PROVIDER}.png\"\n",
        "\n",
        "try:\n",
        "    fixed_extent = merc_extent_from_center(center_lat=CAM_LAT, center_lon=CAM_LON, width_m=WIDTH_M, height_m=HEIGHT_M)\n",
        "    out = save_h3_basemap(\n",
        "        geo_csv=f\"{OUTPUT_DIR}/all_people_geo_calibrated.csv\",\n",
        "        out_png=str(h3_png),\n",
        "        provider=PROVIDER,\n",
        "        zoom=19,  # or None to auto-select\n",
        "        h3_res=H3_RES,\n",
        "        weight_col=None,  # set to 'conf' to sum confidences instead of counts\n",
        "        alpha=0.5,\n",
        "        dpi=150,\n",
        "        margin_frac=0.10,\n",
        "        fixed_extent_merc=fixed_extent,\n",
        "        cmap=\"viridis\",\n",
        "        edgecolor=\"#ffffff\",\n",
        "        linewidth=0.4,\n",
        "    )\n",
        "    print(f\"Saved: {out}\")\n",
        "except Exception as e:\n",
        "    print(\"H3 export requires 'h3' and geopandas/contextily.\")\n",
        "    print(\"Install: pip install h3 'panogeo[geo]'\")\n",
        "    print(\"Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: output\\people_summary_h3_r14_japan_gsi_air.png\n"
          ]
        }
      ],
      "source": [
        "# 6d) Export an H3-aggregated PNG summary map of all detections\n",
        "from pathlib import Path\n",
        "from panogeo.mapplot import save_h3_basemap, merc_extent_from_center\n",
        "\n",
        "OUTPUT_DIR = \"./output\"                # outputs\n",
        "CAM_LAT       = 35.16928165\n",
        "CAM_LON       = 136.90860244\n",
        "\n",
        "PROVIDER = \"japan_gsi_air\"  # \"carto\", \"osm\", \"esri-world\", \"japan_gsi_seamless\", \"japan_gsi_air\", or XYZ URL\n",
        "WIDTH_M = 150.0\n",
        "HEIGHT_M = 150.0\n",
        "H3_RES = 14   # smaller number = larger hexagons (e.g., 8..11)\n",
        "\n",
        "h3_png = Path(OUTPUT_DIR) / f\"people_summary_h3_r{H3_RES}_{PROVIDER}.png\"\n",
        "\n",
        "try:\n",
        "    fixed_extent = merc_extent_from_center(center_lat=CAM_LAT, center_lon=CAM_LON, width_m=WIDTH_M, height_m=HEIGHT_M)\n",
        "    out = save_h3_basemap(\n",
        "        geo_csv=f\"{OUTPUT_DIR}/all_people_geo_calibrated.csv\",\n",
        "        out_png=str(h3_png),\n",
        "        provider=PROVIDER,\n",
        "        zoom=18,  # or None to auto-select\n",
        "        h3_res=H3_RES,\n",
        "        weight_col=None,  # set to 'conf' to sum confidences instead of counts\n",
        "        alpha=0.5,\n",
        "        dpi=150,\n",
        "        margin_frac=0.10,\n",
        "        fixed_extent_merc=fixed_extent,\n",
        "        cmap=\"viridis\",\n",
        "        edgecolor=\"#ffffff\",\n",
        "        linewidth=0.4,\n",
        "    )\n",
        "    print(f\"Saved: {out}\")\n",
        "except Exception as e:\n",
        "    # print(\"H3 export requires 'h3' and geopandas/contextily.\")\n",
        "    # print(\"Install: pip install h3 'panogeo[geo]'\")\n",
        "    print(\"Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# Combine annotated images with corresponding map inset (bigger, white edge, slight offset)\n",
        "annotated_dir = Path('output/annotated')\n",
        "map_dirs = [Path('output/maps_all'), Path('output/maps')]\n",
        "output_dir = Path('output/combined')\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "map_priority = ['japan_gsi_air', 'carto', 'osm']\n",
        "\n",
        "created = 0\n",
        "skipped = []\n",
        "\n",
        "for ann_path in sorted(annotated_dir.glob('*_annotated.jpg')):\n",
        "    base = ann_path.name[:-len('_annotated.jpg')]\n",
        "\n",
        "    # Choose best map\n",
        "    map_path = None\n",
        "    for layer in map_priority:\n",
        "        candidate = None\n",
        "        for d in map_dirs:\n",
        "            p = d / f'{base}_{layer}.png'\n",
        "            if p.exists():\n",
        "                candidate = p\n",
        "                break\n",
        "        if candidate:\n",
        "            map_path = candidate\n",
        "            break\n",
        "    if map_path is None:\n",
        "        for d in map_dirs:\n",
        "            matches = sorted(d.glob(f'{base}_*.png'))\n",
        "            if matches:\n",
        "                map_path = matches[0]\n",
        "                break\n",
        "    if map_path is None:\n",
        "        skipped.append((ann_path.name, 'no map found'))\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        annotated_img = Image.open(ann_path).convert('RGB')\n",
        "        map_img = Image.open(map_path).convert('RGB')\n",
        "\n",
        "        # Height of map inset = panorama height / 2.2\n",
        "        target_h = max(1, int(annotated_img.height / 2.2))\n",
        "        target_w = max(1, int(map_img.width * (target_h / map_img.height)))\n",
        "        inset = map_img.resize((target_w, target_h), Image.LANCZOS)\n",
        "\n",
        "        # White edge border\n",
        "        inset = ImageOps.expand(inset, border=8, fill='white')\n",
        "\n",
        "        # Slight offset from top-left\n",
        "        offset_x = max(10, int(annotated_img.width * 0.015))\n",
        "        offset_y = max(10, int(annotated_img.height * 0.015))\n",
        "\n",
        "        combined = annotated_img.copy()\n",
        "        combined.paste(inset, (offset_x, offset_y))\n",
        "\n",
        "        out_path = output_dir / f'{base}_annotated_with_map.jpg'\n",
        "        combined.save(out_path, quality=92)\n",
        "        created += 1\n",
        "    except Exception as e:\n",
        "        skipped.append((ann_path.name, str(e)))\n",
        "\n",
        "print(f'Created: {created}')\n",
        "if skipped:\n",
        "    print('Skipped:')\n",
        "    for name, reason in skipped[:10]:\n",
        "        print(' -', name, '->', reason)\n",
        "    if len(skipped) > 10:\n",
        "        print(f' ... and {len(skipped) - 10} more')\n",
        "\n",
        "# Preview one\n",
        "try:\n",
        "    from IPython.display import display\n",
        "    examples = sorted(output_dir.glob('*_annotated_with_map.jpg'))\n",
        "    if examples:\n",
        "        display(Image.open(examples[0]))\n",
        "except Exception:\n",
        "    pass\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "panogeo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
