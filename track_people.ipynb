{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q --upgrade ultralytics opencv-python numpy imutils tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83d387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video': 'data/videos/onikuru_cropped_mini.mp4', 'out_dir': 'output\\\\people_track_20251205_124255', 'device': 0, 'imgsz': 1920, 'conf': 0.08, 'iou': 0.45}\n"
     ]
    }
   ],
   "source": [
    "# Self-contained run using panogeo.people_tracking\n",
    "import sys, subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Import module API\n",
    "from panogeo.people_tracking import run_tracking\n",
    "\n",
    "\n",
    "VIDEO_PATH = \"data/videos/onikuru_cropped_mini.mp4\"\n",
    "\n",
    "# Output directory\n",
    "STAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUT_DIR = Path(\"output\") / f\"people_track_{STAMP}\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model choices\n",
    "MODEL_NAME = \"yolo12m.pt\"  # or a local Path\n",
    "\n",
    "# Autodetect device\n",
    "DEVICE = 0\n",
    "\n",
    "# Tuned defaults (small-person friendly)\n",
    "CONF_THRES = 0.08\n",
    "IOU_THRES = 0.45\n",
    "IMG_SIZE = 1920            # set to 3840 for full 4K, may need more VRAM\n",
    "MAX_DET = 3000\n",
    "PERSON_CLASS_ID = 0\n",
    "AGNOSTIC_NMS = True\n",
    "MAX_DISAPPEARED = 30\n",
    "MAX_DISTANCE = 110.0\n",
    "ENABLE_COUNTING = False\n",
    "LINE_Y_FRACTION = 0.55\n",
    "CENTER_CROP = (1920, 1080)\n",
    "SHOW_TRAJ = True\n",
    "\n",
    "print({\n",
    "    \"video\": str(VIDEO_PATH),\n",
    "    \"out_dir\": str(OUT_DIR),\n",
    "    \"device\": DEVICE,\n",
    "    \"imgsz\": IMG_SIZE,\n",
    "    \"conf\": CONF_THRES,\n",
    "    \"iou\": IOU_THRES,\n",
    "})\n",
    "\n",
    "# # Run\n",
    "# module_out = run_tracking(\n",
    "#     video_path=VIDEO_PATH,\n",
    "#     output_path=OUT_DIR / \"_module_full_traj.mp4\",\n",
    "#     model=MODEL_NAME,\n",
    "#     conf_thres=CONF_THRES,\n",
    "#     iou_thres=IOU_THRES,\n",
    "#     imgsz=IMG_SIZE,\n",
    "#     max_det=MAX_DET,\n",
    "#     person_class_id=PERSON_CLASS_ID,\n",
    "#     agnostic_nms=AGNOSTIC_NMS,\n",
    "#     device=DEVICE,\n",
    "#     half=True,\n",
    "#     amp=True,\n",
    "#     enable_counting=ENABLE_COUNTING,\n",
    "#     line_y_fraction=LINE_Y_FRACTION,\n",
    "#     center_crop=CENTER_CROP,\n",
    "#     show_trajectories=SHOW_TRAJ,\n",
    "#     traj_max_points=400,\n",
    "#     traj_thickness=2,\n",
    "#     max_disappeared=MAX_DISAPPEARED,\n",
    "#     max_distance=MAX_DISTANCE,\n",
    "# )\n",
    "# print(f\"Saved via module: {module_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a735b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use case: Calibrate from a video (first frame) with the interactive UI, then solve calibration\n",
    "from pathlib import Path\n",
    "\n",
    "from panogeo import launch_calibration_ui\n",
    "from panogeo.calibration import solve_calibration, save_calibration\n",
    "\n",
    "# Video to calibrate from (first frame will be used)\n",
    "try:\n",
    "    VIDEO_FOR_CALIB = VIDEO_PATH  # reuse from above if defined\n",
    "except NameError:\n",
    "    VIDEO_FOR_CALIB = \"data/videos/onikuru_cropped_mini.mp4\"\n",
    "\n",
    "# Where to save the clicked pixel↔geo pairs\n",
    "CALIB_CSV = \"output/calib_points_onikuru.csv\"\n",
    "\n",
    "# Projection and image shape\n",
    "PROJECTION = \"perspective\"   # \"pano\" or \"perspective\"\n",
    "IMG_W = 1920\n",
    "IMG_H = 1080\n",
    "\n",
    "# Map start center (approximate camera location) — adjust to your scene\n",
    "CAM_LAT = 34.8160832408207\n",
    "CAM_LON = 135.56937219059122\n",
    "CAMERA_ALT_M = 20.0\n",
    "GROUND_ALT_M = 0.0\n",
    "\n",
    "# # Launch the interactive UI (click image then map; press \"Save CSV\")\n",
    "# ui = launch_calibration_ui(\n",
    "#     pano_path=str(VIDEO_FOR_CALIB),\n",
    "#     map_center=(CAM_LAT, CAM_LON),\n",
    "#     map_zoom=18,\n",
    "#     display_width_px=IMG_W,     # render at full width for easier clicking\n",
    "#     default_alt_m=GROUND_ALT_M, # default target altitude when clicking map\n",
    "#     enable_zoom=True,\n",
    "#     image_viewport_height_px=520,\n",
    "#     projection=PROJECTION,\n",
    "# )\n",
    "# ui.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d37ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved perspective homography to: output\\calibration_perspective.npz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# After saving CALIB_CSV in the UI, optionally run the solver below by setting RUN_SOLVE=True\n",
    "RUN_SOLVE = True\n",
    "OUT_DIR = Path(\"output\")\n",
    "if RUN_SOLVE:\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    if str(PROJECTION).strip().lower() == \"perspective\":\n",
    "        # Perspective images: compute pixel->ENU homography (local meters), then store with reference lat/lon\n",
    "        from panogeo.perspective import solve_homography_from_csv, save_homography\n",
    "        H, REF_LAT, REF_LON = solve_homography_from_csv(CALIB_CSV)\n",
    "        out_npz = OUT_DIR / \"calibration_perspective.npz\"\n",
    "        save_homography(str(out_npz), H, ref_lat=REF_LAT, ref_lon=REF_LON, ground_alt_m=0.0)\n",
    "        print(f\"Saved perspective homography to: {out_npz}\")\n",
    "    else:\n",
    "        # Panoramas: solve for camera rotation and position\n",
    "        from panogeo.calibration import solve_calibration, save_calibration\n",
    "        res = solve_calibration(\n",
    "            calib_csv=CALIB_CSV,\n",
    "            cam_lat=CAM_LAT,\n",
    "            cam_lon=CAM_LON,\n",
    "            camera_alt_m=CAMERA_ALT_M,   # e.g., 20.0\n",
    "            ground_alt_m=GROUND_ALT_M,\n",
    "            default_width=IMG_W,\n",
    "            default_height=IMG_H,\n",
    "            optimize_cam_position=False,   # keep cam position fixed\n",
    "        )\n",
    "        out_npz = OUT_DIR / \"calibration_cam2enu_onikuru.npz\"\n",
    "        save_calibration(\n",
    "            npz_path=str(out_npz),\n",
    "            calib=res,\n",
    "            cam_lat=res.cam_lat,\n",
    "            cam_lon=res.cam_lon,\n",
    "            camera_alt_m=res.camera_alt_m,\n",
    "            ground_alt_m=GROUND_ALT_M,\n",
    "        )\n",
    "        print(f\"Saved calibration to: {out_npz}\")\n",
    "        print(f\"yaw={res.yaw_deg:.2f}°, pitch={res.pitch_deg:.2f}°, roll={res.roll_deg:.2f}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0535ecbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video': 'data/videos/onikuru_cropped_mini.mp4', 'out_dir': 'output\\\\people_track_20251205_124303', 'device': 0, 'imgsz': 1920, 'conf': 0.08, 'iou': 0.45}\n",
      "[debug] tracks csv W unique=[3840], H unique=[2160], rows=93656\n",
      "                                  video                         image  frame  \\\n",
      "0  data/videos/onikuru_cropped_mini.mp4  onikuru_cropped_mini_f000001      1   \n",
      "1  data/videos/onikuru_cropped_mini.mp4  onikuru_cropped_mini_f000001      1   \n",
      "2  data/videos/onikuru_cropped_mini.mp4  onikuru_cropped_mini_f000001      1   \n",
      "\n",
      "   track_id     W     H    u_px    v_px  \n",
      "0         0  3840  2160  3236.0  1999.0  \n",
      "1         1  3840  2160  2964.0  1894.0  \n",
      "2         2  3840  2160  1264.0  2159.0  \n",
      "[persp] homography file=output\\calibration_perspective.npz (1410 bytes), type=ENU\n",
      "[persp] ref_lat=34.81718319, ref_lon=135.56929654, ground_alt_m=0.00\n",
      "[persp] gating by calib bbox E[-170.2,170.0] N[-173.3,305.2] margin=120.0 -> keep 93656/93656\n",
      "[persp] ENU stats: E:[-59.49,53.17] N:[-65.76,155.91]\n",
      "[persp] lon:[135.56864631,135.56987768] lat:[34.81659041,34.81858855]\n",
      "Geolocated CSV: output\\people_track_20251205_124303\\all_people_geo_calibrated.csv\n",
      "[debug] lon:[ 135.56864631464083 , 135.56987767518729 ] lat:[ 34.8165904064263 , 34.8185885459386 ]\n",
      "                                  video                         image  frame  \\\n",
      "0  data/videos/onikuru_cropped_mini.mp4  onikuru_cropped_mini_f000001      1   \n",
      "1  data/videos/onikuru_cropped_mini.mp4  onikuru_cropped_mini_f000001      1   \n",
      "2  data/videos/onikuru_cropped_mini.mp4  onikuru_cropped_mini_f000001      1   \n",
      "\n",
      "   track_id     W     H    u_px    v_px         lon        lat     east_m  \\\n",
      "0         0  3840  2160  3236.0  1999.0  135.569617  34.816739  29.281183   \n",
      "1         1  3840  2160  2964.0  1894.0  135.569564  34.816772  24.466045   \n",
      "2         2  3840  2160  1264.0  2159.0  135.569220  34.816624  -7.034914   \n",
      "\n",
      "     north_m  \n",
      "0 -49.226604  \n",
      "1 -45.636658  \n",
      "2 -62.072788  \n",
      "[map-video] frame 1/615\n",
      "[map-video] frame 26/615\n",
      "[map-video] frame 51/615\n",
      "[map-video] frame 76/615\n",
      "[map-video] frame 101/615\n",
      "[map-video] frame 126/615\n",
      "[map-video] frame 151/615\n",
      "[map-video] frame 176/615\n",
      "[map-video] frame 201/615\n",
      "[map-video] frame 226/615\n",
      "[map-video] frame 251/615\n",
      "[map-video] frame 276/615\n",
      "[map-video] frame 301/615\n",
      "[map-video] frame 326/615\n",
      "[map-video] frame 351/615\n",
      "[map-video] frame 376/615\n",
      "[map-video] frame 401/615\n",
      "[map-video] frame 426/615\n",
      "[map-video] frame 451/615\n",
      "[map-video] frame 476/615\n",
      "[map-video] frame 501/615\n",
      "[map-video] frame 526/615\n",
      "[map-video] frame 551/615\n",
      "[map-video] frame 576/615\n",
      "[map-video] frame 601/615\n",
      "Saved map video: output\\people_track_20251205_124303\\people_tracking_map.mp4\n",
      "Saved map: output\\people_track_20251205_124303\\people_tracking_map_carto.png\n"
     ]
    }
   ],
   "source": [
    "# Geolocate tracked people and render a basemap video with trajectories (and PNG debug)\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from panogeo.people_tracking import run_tracking\n",
    "from panogeo.geolocate import geolocate_detections\n",
    "from panogeo.perspective import geolocate_detections_perspective\n",
    "from panogeo.mapplot import save_points_basemap, save_tracking_map_video\n",
    "\n",
    "VIDEO_PATH = \"data/videos/onikuru_cropped_mini.mp4\"\n",
    "\n",
    "# Output directory\n",
    "STAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUT_DIR = Path(\"output\") / f\"people_track_{STAMP}\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model choices\n",
    "MODEL_NAME = \"yolo12m.pt\"  # or a local Path\n",
    "\n",
    "# Autodetect device\n",
    "DEVICE = 0\n",
    "\n",
    "# Tuned defaults (small-person friendly)\n",
    "PROJECTION = \"perspective\"   # \"pano\" or \"perspective\"\n",
    "CONF_THRES = 0.08\n",
    "IOU_THRES = 0.45\n",
    "IMG_SIZE = 1920            # set to 3840 for full 4K, may need more VRAM\n",
    "MAX_DET = 3000\n",
    "PERSON_CLASS_ID = 0\n",
    "AGNOSTIC_NMS = True\n",
    "MAX_DISAPPEARED = 30\n",
    "MAX_DISTANCE = 110.0\n",
    "ENABLE_COUNTING = False\n",
    "LINE_Y_FRACTION = 0.55\n",
    "CENTER_CROP = None\n",
    "SHOW_TRAJ = True\n",
    "\n",
    "print({\n",
    "    \"video\": str(VIDEO_PATH),\n",
    "    \"out_dir\": str(OUT_DIR),\n",
    "    \"device\": DEVICE,\n",
    "    \"imgsz\": IMG_SIZE,\n",
    "    \"conf\": CONF_THRES,\n",
    "    \"iou\": IOU_THRES,\n",
    "})\n",
    "\n",
    "# Paths\n",
    "TRACK_EXPORT_CSV = OUT_DIR / \"tracks_points.csv\"   # OUT_DIR from the tracking cell (timestamped)\n",
    "CALIB_PANO_NPZ = Path(\"output\") / \"calibration_cam2enu_onikuru.npz\"\n",
    "CALIB_PERSP_NPZ = Path(\"output\") / \"calibration_perspective.npz\"\n",
    "\n",
    "# 1) Re-run tracking with CSV export enabled (keeps the same video output path)\n",
    "_ = run_tracking(\n",
    "    video_path=VIDEO_PATH,\n",
    "    output_path=OUT_DIR / \"_module_full_traj.mp4\",\n",
    "    model=MODEL_NAME,\n",
    "    conf_thres=CONF_THRES,\n",
    "    iou_thres=IOU_THRES,\n",
    "    imgsz=IMG_SIZE,\n",
    "    max_det=MAX_DET,\n",
    "    person_class_id=PERSON_CLASS_ID,\n",
    "    agnostic_nms=AGNOSTIC_NMS,\n",
    "    device=DEVICE,\n",
    "    half=True,\n",
    "    amp=True,\n",
    "    enable_counting=False,\n",
    "    line_y_fraction=LINE_Y_FRACTION,\n",
    "    center_crop=CENTER_CROP,\n",
    "    show_trajectories=False,    # faster, we already have a video with trajectories\n",
    "    traj_max_points=200,\n",
    "    traj_thickness=2,\n",
    "    max_disappeared=MAX_DISAPPEARED,\n",
    "    max_distance=MAX_DISTANCE,\n",
    "    export_csv_path=TRACK_EXPORT_CSV,\n",
    ")\n",
    "\n",
    "# Debug: check detection export W/H and a few samples\n",
    "try:\n",
    "    det_df = pd.read_csv(TRACK_EXPORT_CSV)\n",
    "    w_set = sorted(det_df[\"W\"].astype(int).unique().tolist())\n",
    "    h_set = sorted(det_df[\"H\"].astype(int).unique().tolist())\n",
    "    print(f\"[debug] tracks csv W unique={w_set}, H unique={h_set}, rows={len(det_df)}\")\n",
    "    print(det_df.head(3))\n",
    "except Exception as e:\n",
    "    print(\"[debug] failed reading tracks csv:\", e)\n",
    "\n",
    "# 2) Geolocate the exported track points\n",
    "try:\n",
    "    if str(PROJECTION).strip().lower() == \"perspective\":\n",
    "        xy_csv, geo_csv = geolocate_detections_perspective(\n",
    "            detections_csv=str(TRACK_EXPORT_CSV),\n",
    "            homography_npz=str(CALIB_PERSP_NPZ),\n",
    "            output_dir=str(OUT_DIR),\n",
    "            debug=True,\n",
    "            calib_csv=(str(CALIB_CSV) if 'CALIB_CSV' in globals() else None),\n",
    "            gate_margin_m=120.0,\n",
    "            drop_outside=True,\n",
    "        )\n",
    "    else:\n",
    "        xy_csv, geo_csv = geolocate_detections(\n",
    "            detections_csv=str(TRACK_EXPORT_CSV),\n",
    "            calibration_npz=str(CALIB_PANO_NPZ),\n",
    "            output_dir=str(OUT_DIR),\n",
    "        )\n",
    "    print(\"Geolocated CSV:\", geo_csv)\n",
    "except Exception as e:\n",
    "    print(\"[debug] geolocate failed:\", e)\n",
    "    raise\n",
    "\n",
    "# Quick debug: show lon/lat and range stats\n",
    "try:\n",
    "    gdf = pd.read_csv(geo_csv)\n",
    "    if not gdf.empty:\n",
    "        print(\n",
    "            \"[debug] lon:[\", float(gdf[\"lon\"].min()), \",\", float(gdf[\"lon\"].max()), \"]\",\n",
    "            \"lat:[\", float(gdf[\"lat\"].min()), \",\", float(gdf[\"lat\"].max()), \"]\",\n",
    "        )\n",
    "        if \"range_m\" in gdf.columns:\n",
    "            print(\n",
    "                \"[debug] range_m stats min/mean/max:\",\n",
    "                float(gdf[\"range_m\"].min()),\n",
    "                float(gdf[\"range_m\"].mean()),\n",
    "                float(gdf[\"range_m\"].max()),\n",
    "            )\n",
    "        print(gdf.head(3))\n",
    "except Exception as e:\n",
    "    print(\"[debug] failed reading geo csv:\", e)\n",
    "\n",
    "# 3) Render a basemap video of geolocated tracks with trajectories\n",
    "MAP_MP4 = OUT_DIR / \"people_tracking_map.mp4\"\n",
    "try:\n",
    "    out_mp4 = save_tracking_map_video(\n",
    "        geo_csv=str(geo_csv),\n",
    "        out_mp4=str(MAP_MP4),\n",
    "        provider=\"japan_gsi_air\",\n",
    "        zoom=None,\n",
    "        point_size=20.0,\n",
    "        alpha=0.95,\n",
    "        traj_max_frames=200,\n",
    "        dpi=150,\n",
    "        margin_frac=0.10,\n",
    "        fps=20.0,\n",
    "    )\n",
    "    print(\"Saved map video:\", out_mp4)\n",
    "except Exception as e:\n",
    "    print(\"[debug] map video failed:\", e)\n",
    "\n",
    "# Optional: also export single PNG basemap of all points\n",
    "MAP_PNG = OUT_DIR / \"people_tracking_map_carto.png\"\n",
    "out_png = save_points_basemap(\n",
    "    geo_csv=str(geo_csv),\n",
    "    out_png=str(MAP_PNG),\n",
    "    provider=\"japan_gsi_air\",\n",
    "    zoom=None,\n",
    "    point_size=12.0,\n",
    "    alpha=0.9,\n",
    "    point_color=\"#FF5722\",\n",
    "    dpi=150,\n",
    ")\n",
    "print(\"Saved map:\", out_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c59b43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panogeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
