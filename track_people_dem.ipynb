{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q --upgrade ultralytics opencv-python numpy imutils tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83d387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video': 'data/videos/onikuru_cropped_mini.mp4', 'out_dir': 'output\\\\people_track_20251207_222333', 'device': 0, 'imgsz': 1920, 'conf': 0.08, 'iou': 0.45}\n"
     ]
    }
   ],
   "source": [
    "# Self-contained run using panogeo.people_tracking\n",
    "import sys, subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Import module API\n",
    "from panogeo.people_tracking import run_tracking\n",
    "\n",
    "\n",
    "VIDEO_PATH = \"data/videos/onikuru_cropped_mini.mp4\"\n",
    "\n",
    "# Output directory\n",
    "STAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUT_DIR = Path(\"output\") / f\"people_track_{STAMP}\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model choices\n",
    "MODEL_NAME = \"yolo12m.pt\"  # or a local Path\n",
    "\n",
    "# Autodetect device\n",
    "DEVICE = 0\n",
    "\n",
    "# Tuned defaults (small-person friendly)\n",
    "CONF_THRES = 0.08\n",
    "IOU_THRES = 0.45\n",
    "IMG_SIZE = 1920            # set to 3840 for full 4K, may need more VRAM\n",
    "MAX_DET = 3000\n",
    "PERSON_CLASS_ID = 0\n",
    "AGNOSTIC_NMS = True\n",
    "MAX_DISAPPEARED = 30\n",
    "MAX_DISTANCE = 110.0\n",
    "ENABLE_COUNTING = False\n",
    "LINE_Y_FRACTION = 0.55\n",
    "CENTER_CROP = (1920, 1080)\n",
    "SHOW_TRAJ = True\n",
    "\n",
    "print({\n",
    "    \"video\": str(VIDEO_PATH),\n",
    "    \"out_dir\": str(OUT_DIR),\n",
    "    \"device\": DEVICE,\n",
    "    \"imgsz\": IMG_SIZE,\n",
    "    \"conf\": CONF_THRES,\n",
    "    \"iou\": IOU_THRES,\n",
    "})\n",
    "\n",
    "# # Run\n",
    "# module_out = run_tracking(\n",
    "#     video_path=VIDEO_PATH,\n",
    "#     output_path=OUT_DIR / \"_module_full_traj.mp4\",\n",
    "#     model=MODEL_NAME,\n",
    "#     conf_thres=CONF_THRES,\n",
    "#     iou_thres=IOU_THRES,\n",
    "#     imgsz=IMG_SIZE,\n",
    "#     max_det=MAX_DET,\n",
    "#     person_class_id=PERSON_CLASS_ID,\n",
    "#     agnostic_nms=AGNOSTIC_NMS,\n",
    "#     device=DEVICE,\n",
    "#     half=True,\n",
    "#     amp=True,\n",
    "#     enable_counting=ENABLE_COUNTING,\n",
    "#     line_y_fraction=LINE_Y_FRACTION,\n",
    "#     center_crop=CENTER_CROP,\n",
    "#     show_trajectories=SHOW_TRAJ,\n",
    "#     traj_max_points=400,\n",
    "#     traj_thickness=2,\n",
    "#     max_disappeared=MAX_DISAPPEARED,\n",
    "#     max_distance=MAX_DISTANCE,\n",
    "# )\n",
    "# print(f\"Saved via module: {module_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a735b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use case: Calibrate from a video (first frame) with the interactive UI, then solve calibration\n",
    "from pathlib import Path\n",
    "\n",
    "from panogeo import launch_calibration_ui\n",
    "from panogeo.calibration import solve_calibration, save_calibration\n",
    "\n",
    "# Video to calibrate from (first frame will be used)\n",
    "try:\n",
    "    VIDEO_FOR_CALIB = VIDEO_PATH  # reuse from above if defined\n",
    "except NameError:\n",
    "    VIDEO_FOR_CALIB = \"data/videos/onikuru_cropped_mini.mp4\"\n",
    "\n",
    "# Where to save the clicked pixel↔geo pairs\n",
    "CALIB_CSV = \"output/calib_points_onikuru.csv\"\n",
    "\n",
    "# Projection and image shape\n",
    "PROJECTION = \"perspective\"   # \"pano\" or \"perspective\"\n",
    "IMG_W = 1920\n",
    "IMG_H = 1080\n",
    "\n",
    "# Map start center (approximate camera location) — adjust to your scene\n",
    "CAM_LAT = 34.8160832408207\n",
    "CAM_LON = 135.56937219059122\n",
    "CAMERA_ALT_M = 20.0\n",
    "GROUND_ALT_M = 0.0\n",
    "\n",
    "# # Launch the interactive UI (click image then map; press \"Save CSV\")\n",
    "# ui = launch_calibration_ui(\n",
    "#     pano_path=str(VIDEO_FOR_CALIB),\n",
    "#     map_center=(CAM_LAT, CAM_LON),\n",
    "#     map_zoom=18,\n",
    "#     display_width_px=IMG_W,     # render at full width for easier clicking\n",
    "#     default_alt_m=GROUND_ALT_M, # default target altitude when clicking map\n",
    "#     enable_zoom=True,\n",
    "#     image_viewport_height_px=520,\n",
    "#     projection=PROJECTION,\n",
    "# )\n",
    "# ui.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d37ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved perspective homography to: output\\calibration_perspective.npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# After saving CALIB_CSV in the UI, optionally run the solver below by setting RUN_SOLVE=True\n",
    "RUN_SOLVE = True\n",
    "OUT_DIR = Path(\"output\")\n",
    "if RUN_SOLVE:\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    if str(PROJECTION).strip().lower() == \"perspective\":\n",
    "        # Perspective images: compute pixel->ENU homography (local meters), then store with reference lat/lon\n",
    "        from panogeo.perspective import solve_homography_from_csv, save_homography\n",
    "        H, REF_LAT, REF_LON = solve_homography_from_csv(CALIB_CSV)\n",
    "        out_npz = OUT_DIR / \"calibration_perspective.npz\"\n",
    "        save_homography(\n",
    "            str(out_npz),\n",
    "            H,\n",
    "            ref_lat=REF_LAT,\n",
    "            ref_lon=REF_LON,\n",
    "            ground_alt_m=0.0,\n",
    "            calib_csv=CALIB_CSV,\n",
    "            google_api_key=os.getenv(\"GOOGLE_MAPS_API_KEY\"),\n",
    "        )\n",
    "        print(f\"Saved perspective homography to: {out_npz}\")\n",
    "    else:\n",
    "        # Panoramas: solve for camera rotation and position\n",
    "        from panogeo.calibration import solve_calibration, save_calibration\n",
    "        res = solve_calibration(\n",
    "            calib_csv=CALIB_CSV,\n",
    "            cam_lat=CAM_LAT,\n",
    "            cam_lon=CAM_LON,\n",
    "            camera_alt_m=CAMERA_ALT_M,   # e.g., 20.0\n",
    "            ground_alt_m=GROUND_ALT_M,\n",
    "            default_width=IMG_W,\n",
    "            default_height=IMG_H,\n",
    "            optimize_cam_position=False,   # keep cam position fixed\n",
    "            dem_path=(str(DEM_PATH) if 'DEM_PATH' in globals() and DEM_PATH else None),\n",
    "            google_api_key=os.getenv(\"GOOGLE_MAPS_API_KEY\"),\n",
    "        )\n",
    "        out_npz = OUT_DIR / \"calibration_cam2enu_onikuru.npz\"\n",
    "        save_calibration(\n",
    "            npz_path=str(out_npz),\n",
    "            calib=res,\n",
    "            cam_lat=res.cam_lat,\n",
    "            cam_lon=res.cam_lon,\n",
    "            camera_alt_m=res.camera_alt_m,\n",
    "            ground_alt_m=GROUND_ALT_M,\n",
    "        )\n",
    "        print(f\"Saved calibration to: {out_npz}\")\n",
    "        print(f\"yaw={res.yaw_deg:.2f}°, pitch={res.pitch_deg:.2f}°, roll={res.roll_deg:.2f}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0535ecbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video': 'data/videos/onikuru_cropped_mini.mp4', 'out_dir': 'output\\\\people_track_20251207_002739', 'device': 0, 'imgsz': 1920, 'conf': 0.08, 'iou': 0.45}\n",
      "[debug] tracks csv W unique=[1920], H unique=[1080], rows=71168\n",
      "                                  video                         image  frame  \\\n",
      "0  data/videos/onikuru_cropped_mini.mp4  onikuru_cropped_mini_f000001      1   \n",
      "1  data/videos/onikuru_cropped_mini.mp4  onikuru_cropped_mini_f000001      1   \n",
      "2  data/videos/onikuru_cropped_mini.mp4  onikuru_cropped_mini_f000001      1   \n",
      "\n",
      "   track_id     W     H  x_offset_px  y_offset_px  SRC_W  SRC_H    u_px  \\\n",
      "0         0  1920  1080          960          540   3840   2160  1122.0   \n",
      "1         1  1920  1080          960          540   3840   2160  1807.0   \n",
      "2         2  1920  1080          960          540   3840   2160  1835.0   \n",
      "\n",
      "     v_px  \n",
      "0   396.0  \n",
      "1  1021.0  \n",
      "2   794.0  \n",
      "[persp] homography file=output\\calibration_perspective.npz (1410 bytes), type=ENU\n",
      "[persp] ref_lat=34.81718319, ref_lon=135.56929654, ground_alt_m=0.00\n",
      "[persp] applied crop offsets: mean x_offset=960.0, y_offset=540.0\n",
      "[geolocate-persp] 10000/71168\n",
      "[geolocate-persp] 20000/71168\n",
      "[geolocate-persp] 30000/71168\n",
      "[geolocate-persp] 40000/71168\n",
      "[geolocate-persp] 50000/71168\n",
      "[geolocate-persp] 60000/71168\n",
      "[geolocate-persp] 70000/71168\n",
      "[geolocate-persp] 71168/71168\n",
      "[persp] gating by calib bbox E[-170.2,170.0] N[-173.3,305.2] margin=120.0 -> keep 71168/71168\n",
      "[persp] ENU stats: E:[-37.57,32.35] N:[-33.09,157.12]\n",
      "[persp] lon:[135.56888595,135.56965011] lat:[34.81688493,34.81859945]\n",
      "Geolocated CSV: output\\people_track_20251207_002739\\all_people_geo_calibrated.csv\n",
      "[debug] lon:[ 135.56888595473094 , 135.56965011401158 ] lat:[ 34.81688492744336 , 34.81859945200964 ]\n",
      "                                  video                         image  frame  \\\n",
      "0  data/videos/onikuru_cropped_mini.mp4  onikuru_cropped_mini_f000001      1   \n",
      "1  data/videos/onikuru_cropped_mini.mp4  onikuru_cropped_mini_f000001      1   \n",
      "2  data/videos/onikuru_cropped_mini.mp4  onikuru_cropped_mini_f000001      1   \n",
      "\n",
      "   track_id     W     H  x_offset_px  y_offset_px  SRC_W  SRC_H    u_px  \\\n",
      "0         0  1920  1080          960          540   3840   2160  1122.0   \n",
      "1         1  1920  1080          960          540   3840   2160  1807.0   \n",
      "2         2  1920  1080          960          540   3840   2160  1835.0   \n",
      "\n",
      "     v_px         lon        lat     east_m    north_m  \n",
      "0   396.0  135.569269  34.817593  -2.517795  45.487206  \n",
      "1  1021.0  135.569538  34.816938  22.074013 -27.212414  \n",
      "2   794.0  135.569567  34.817117  24.776991  -7.335385  \n",
      "[basemap] Created Google Map Tiles session token\n",
      "[basemap] Using Google Satellite (Map Tiles API, session-based, 2dtiles z/x/y)\n",
      "[map-video] frame 1/615\n",
      "[map-video] frame 26/615\n",
      "[map-video] frame 51/615\n",
      "[map-video] frame 76/615\n",
      "[map-video] frame 101/615\n",
      "[map-video] frame 126/615\n",
      "[map-video] frame 151/615\n",
      "[map-video] frame 176/615\n",
      "[map-video] frame 201/615\n",
      "[map-video] frame 226/615\n",
      "[map-video] frame 251/615\n",
      "[map-video] frame 276/615\n",
      "[map-video] frame 301/615\n",
      "[map-video] frame 326/615\n",
      "[map-video] frame 351/615\n",
      "[map-video] frame 376/615\n",
      "[map-video] frame 401/615\n",
      "[map-video] frame 426/615\n",
      "[map-video] frame 451/615\n",
      "[map-video] frame 476/615\n",
      "[map-video] frame 501/615\n",
      "[map-video] frame 526/615\n",
      "[map-video] frame 551/615\n",
      "[map-video] frame 576/615\n",
      "[map-video] frame 601/615\n",
      "Saved map video: output\\people_track_20251207_002739\\people_tracking_map.mp4\n",
      "[basemap] Using Google Satellite (Map Tiles API, session-based, 2dtiles z/x/y)\n",
      "Saved map: output\\people_track_20251207_002739\\people_tracking_map_carto.png\n"
     ]
    }
   ],
   "source": [
    "# Geolocate tracked people and render a basemap video with trajectories (and PNG debug)\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from panogeo.people_tracking import run_tracking\n",
    "from panogeo.geolocate import geolocate_detections\n",
    "from panogeo.perspective import geolocate_detections_perspective\n",
    "from panogeo.mapplot import save_points_basemap, save_tracking_map_video\n",
    "from panogeo.video import compose_side_by_side_video\n",
    "import cv2\n",
    "\n",
    "VIDEO_PATH = \"data/videos/onikuru_cropped_mini.mp4\"\n",
    "\n",
    "# Output directory\n",
    "STAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUT_DIR = Path(\"output\") / f\"people_track_{STAMP}\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Google Map Tiles API key (optional)\n",
    "GOOGLE_MAPS_API_KEY = os.getenv(\"GOOGLE_MAPS_API_KEY\")\n",
    "\n",
    "# Model choices\n",
    "MODEL_NAME = \"yolo12m.pt\"  # or a local Path\n",
    "\n",
    "# Autodetect device\n",
    "DEVICE = 0\n",
    "\n",
    "# Tuned defaults (small-person friendly)\n",
    "PROJECTION = \"perspective\"   # \"pano\" or \"perspective\"\n",
    "CONF_THRES = 0.08\n",
    "IOU_THRES = 0.45\n",
    "IMG_SIZE = 1920            # set to 3840 for full 4K, may need more VRAM\n",
    "MAX_DET = 3000\n",
    "PERSON_CLASS_ID = 0\n",
    "AGNOSTIC_NMS = True\n",
    "MAX_DISAPPEARED = 30\n",
    "MAX_DISTANCE = 110.0\n",
    "ENABLE_COUNTING = False\n",
    "LINE_Y_FRACTION = 0.55\n",
    "CENTER_CROP = (1920, 1080)\n",
    "SHOW_TRAJ = True\n",
    "\n",
    "print({\n",
    "    \"video\": str(VIDEO_PATH),\n",
    "    \"out_dir\": str(OUT_DIR),\n",
    "    \"device\": DEVICE,\n",
    "    \"imgsz\": IMG_SIZE,\n",
    "    \"conf\": CONF_THRES,\n",
    "    \"iou\": IOU_THRES,\n",
    "})\n",
    "\n",
    "# Paths\n",
    "TRACK_EXPORT_CSV = OUT_DIR / \"tracks_points.csv\"   # OUT_DIR from the tracking cell (timestamped)\n",
    "CALIB_PANO_NPZ = Path(\"output\") / \"calibration_cam2enu_onikuru.npz\"\n",
    "CALIB_PERSP_NPZ = Path(\"output\") / \"calibration_perspective.npz\"\n",
    "\n",
    "# 1) Re-run tracking with CSV export enabled (keeps the same video output path)\n",
    "# Ensure we use the source video's FPS so the composed side-by-side stays in sync\n",
    "cap0 = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "video_fps = cap0.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "cap0.close() if hasattr(cap0, \"close\") else cap0.release()\n",
    "CAM_MP4 = OUT_DIR / \"_module_full_traj.mp4\"\n",
    "\n",
    "_ = run_tracking(\n",
    "    video_path=VIDEO_PATH,\n",
    "    output_path=CAM_MP4,\n",
    "    model=MODEL_NAME,\n",
    "    conf_thres=CONF_THRES,\n",
    "    iou_thres=IOU_THRES,\n",
    "    imgsz=IMG_SIZE,\n",
    "    max_det=MAX_DET,\n",
    "    person_class_id=PERSON_CLASS_ID,\n",
    "    agnostic_nms=AGNOSTIC_NMS,\n",
    "    device=DEVICE,\n",
    "    half=True,\n",
    "    amp=True,\n",
    "    enable_counting=False,\n",
    "    line_y_fraction=LINE_Y_FRACTION,\n",
    "    center_crop=CENTER_CROP,\n",
    "    show_trajectories=True,    # render trajectories for camera view\n",
    "    traj_max_points=200,\n",
    "    traj_thickness=2,\n",
    "    max_disappeared=MAX_DISAPPEARED,\n",
    "    max_distance=MAX_DISTANCE,\n",
    "    export_csv_path=TRACK_EXPORT_CSV,\n",
    "    show_progress=True,\n",
    "    progress_desc=\"Tracking (center-crop)\",\n",
    ")\n",
    "\n",
    "# Debug: check detection export W/H and a few samples\n",
    "try:\n",
    "    det_df = pd.read_csv(TRACK_EXPORT_CSV)\n",
    "    w_set = sorted(det_df[\"W\"].astype(int).unique().tolist())\n",
    "    h_set = sorted(det_df[\"H\"].astype(int).unique().tolist())\n",
    "    print(f\"[debug] tracks csv W unique={w_set}, H unique={h_set}, rows={len(det_df)}\")\n",
    "    print(det_df.head(3))\n",
    "except Exception as e:\n",
    "    print(\"[debug] failed reading tracks csv:\", e)\n",
    "\n",
    "# 2) Geolocate the exported track points\n",
    "try:\n",
    "    if str(PROJECTION).strip().lower() == \"perspective\":\n",
    "        xy_csv, geo_csv = geolocate_detections_perspective(\n",
    "            detections_csv=str(TRACK_EXPORT_CSV),\n",
    "            homography_npz=str(CALIB_PERSP_NPZ),\n",
    "            output_dir=str(OUT_DIR),\n",
    "            debug=True,\n",
    "            calib_csv=(str(CALIB_CSV) if 'CALIB_CSV' in globals() else None),\n",
    "            gate_margin_m=120.0,\n",
    "            drop_outside=True,\n",
    "            show_progress=True,\n",
    "            progress_desc=\"Geolocate (perspective)\",\n",
    "        )\n",
    "    else:\n",
    "        xy_csv, geo_csv = geolocate_detections(\n",
    "            detections_csv=str(TRACK_EXPORT_CSV),\n",
    "            calibration_npz=str(CALIB_PANO_NPZ),\n",
    "            output_dir=str(OUT_DIR),\n",
    "            dem_path=(str(DEM_PATH) if 'DEM_PATH' in globals() and DEM_PATH else None),\n",
    "            show_progress=True,\n",
    "            progress_desc=\"Geolocate (pano)\",\n",
    "            google_api_key=GOOGLE_MAPS_API_KEY,\n",
    "            elev_rows=32,\n",
    "            elev_cols=32,\n",
    "            elev_margin_m=120.0,\n",
    "        )\n",
    "    print(\"Geolocated CSV:\", geo_csv)\n",
    "except Exception as e:\n",
    "    print(\"[debug] geolocate failed:\", e)\n",
    "    raise\n",
    "\n",
    "# Quick debug: show lon/lat and range stats\n",
    "try:\n",
    "    gdf = pd.read_csv(geo_csv)\n",
    "    if not gdf.empty:\n",
    "        print(\n",
    "            \"[debug] lon:[\", float(gdf[\"lon\"].min()), \",\", float(gdf[\"lon\"].max()), \"]\",\n",
    "            \"lat:[\", float(gdf[\"lat\"].min()), \",\", float(gdf[\"lat\"].max()), \"]\",\n",
    "        )\n",
    "        if \"range_m\" in gdf.columns:\n",
    "            print(\n",
    "                \"[debug] range_m stats min/mean/max:\",\n",
    "                float(gdf[\"range_m\"].min()),\n",
    "                float(gdf[\"range_m\"].mean()),\n",
    "                float(gdf[\"range_m\"].max()),\n",
    "            )\n",
    "        print(gdf.head(3))\n",
    "except Exception as e:\n",
    "    print(\"[debug] failed reading geo csv:\", e)\n",
    "\n",
    "# 3) Render a basemap video of geolocated tracks with trajectories\n",
    "MAP_MP4 = OUT_DIR / \"people_tracking_map.mp4\"\n",
    "try:\n",
    "    out_mp4 = save_tracking_map_video(\n",
    "        geo_csv=str(geo_csv),\n",
    "        out_mp4=str(MAP_MP4),\n",
    "        provider=\"google\",\n",
    "        zoom=None,\n",
    "        api_key=GOOGLE_MAPS_API_KEY,\n",
    "        point_size=20.0,\n",
    "        alpha=0.95,\n",
    "        traj_max_frames=200,\n",
    "        dpi=150,\n",
    "        margin_frac=0.10,\n",
    "        fps=video_fps,\n",
    "        show_progress=True,\n",
    "        progress_desc=\"Map video\",\n",
    "    )\n",
    "    print(\"Saved map video:\", out_mp4)\n",
    "except Exception as e:\n",
    "    print(\"[debug] map video failed:\", e)\n",
    "\n",
    "# Optional: also export single PNG basemap of all points\n",
    "MAP_PNG = OUT_DIR / \"people_tracking_map_carto.png\"\n",
    "out_png = save_points_basemap(\n",
    "    geo_csv=str(geo_csv),\n",
    "    out_png=str(MAP_PNG),\n",
    "    provider=\"google\",\n",
    "    zoom=None,\n",
    "    api_key=GOOGLE_MAPS_API_KEY,\n",
    "    point_size=12.0,\n",
    "    alpha=0.9,\n",
    "    point_color=\"#FF5722\",\n",
    "    dpi=150,\n",
    ")\n",
    "print(\"Saved map:\", out_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db1380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[compose] using codec=avc1, size=(2322x1080) @ 30.00fps\n",
      "[compose] frame 30/615\n",
      "[compose] frame 60/615\n",
      "[compose] frame 90/615\n",
      "[compose] frame 120/615\n",
      "[compose] frame 150/615\n",
      "[compose] frame 180/615\n",
      "[compose] frame 210/615\n",
      "[compose] frame 240/615\n",
      "[compose] frame 270/615\n",
      "[compose] frame 300/615\n",
      "[compose] frame 330/615\n",
      "[compose] frame 360/615\n",
      "[compose] frame 390/615\n",
      "[compose] frame 420/615\n",
      "[compose] frame 450/615\n",
      "[compose] frame 480/615\n",
      "[compose] frame 510/615\n",
      "[compose] frame 540/615\n",
      "[compose] frame 570/615\n",
      "[compose] frame 600/615\n",
      "Saved combined video: output\\people_track_20251207_002739\\people_tracking_split.mp4\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 5) Compose side-by-side video: camera view (with trajectories) + map view (with trajectories)\n",
    "from panogeo.video import compose_side_by_side_video\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# OUT_DIR = Path(\"C:/Users/kunih/OneDrive/00_Codes/python/panogeo/output/people_track_20251205_140947\")\n",
    "\n",
    "cam_video = str(OUT_DIR / \"_module_full_traj.mp4\")\n",
    "map_video = str(OUT_DIR / \"people_tracking_map.mp4\")\n",
    "# Write MP4; function will try H.264/avc1 first and fall back if needed\n",
    "out_video = str(OUT_DIR / \"people_tracking_split.mp4\")\n",
    "\n",
    "# Use camera video's fps for consistent playback\n",
    "cap = cv2.VideoCapture(cam_video)\n",
    "compose_fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "cap.release()\n",
    "\n",
    "out_path = compose_side_by_side_video(cam_video, map_video, out_video, layout=\"h\", fps=compose_fps, gap=8)\n",
    "print(\"Saved combined video:\", out_path)\n",
    "\n",
    "# Fallback (uncomment if MP4 is not playable in your default player)\n",
    "# out_video_avi = str(OUT_DIR / \"people_tracking_split.avi\")\n",
    "# out_path = compose_side_by_side_video(cam_video, map_video, out_video_avi, layout=\"h\", fps=compose_fps, gap=8, codec=\"XVID\")\n",
    "# print(\"Saved combined video (AVI):\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## verify downloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1934062b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[verify] saved: output\\google_static_test.png\n",
      "[verify] url: https://maps.googleapis.com/maps/api/staticmap?center=34.81739831%2C135.56928846&zoom=17&size=640x640&scale=2&maptype=satellite&key=AIzaSyCxwDDGsp_YFnk1pPInn3ofmQmtKBgbYv8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kunih\\AppData\\Local\\Temp\\ipykernel_45296\\4006522768.py:77: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Verify Google Satellite download (Static Maps)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Read API key\n",
    "API_KEY = os.getenv(\"GOOGLE_MAPS_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"GOOGLE_MAPS_API_KEY is not set. Set it in env or os.environ before running this cell.\")\n",
    "\n",
    "# 2) Choose center/zoom from current geo_csv if available; else use defaults\n",
    "center_lat, center_lon, zoom = None, None, 17\n",
    "try:\n",
    "    if 'geo_csv' in globals():\n",
    "        import pandas as pd\n",
    "        _df = pd.read_csv(geo_csv)\n",
    "        if (\"lat\" in _df.columns) and (\"lon\" in _df.columns) and not _df.empty:\n",
    "            center_lat = float(_df[\"lat\"].astype(float).mean())\n",
    "            center_lon = float(_df[\"lon\"].astype(float).mean())\n",
    "except Exception as _e:\n",
    "    print(\"[verify] failed to read geo_csv for center:\", _e)\n",
    "\n",
    "# Fallback center (near your sample data)\n",
    "if center_lat is None or center_lon is None:\n",
    "    center_lat = 34.8172\n",
    "    center_lon = 135.5693\n",
    "\n",
    "# 3) Build and fetch Static Maps URL (satellite), size limited to 640x640 at scale=2\n",
    "base_url = \"https://maps.googleapis.com/maps/api/staticmap\"\n",
    "params = {\n",
    "    \"center\": f\"{center_lat:.8f},{center_lon:.8f}\",\n",
    "    \"zoom\": str(int(zoom)),\n",
    "    \"size\": \"640x640\",\n",
    "    \"scale\": \"2\",\n",
    "    \"maptype\": \"satellite\",\n",
    "    \"key\": API_KEY,\n",
    "}\n",
    "\n",
    "# Prefer requests; fallback to urllib\n",
    "img_bytes = None\n",
    "fetch_url = None\n",
    "try:\n",
    "    import requests\n",
    "    r = requests.get(base_url, params=params, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    img_bytes = r.content\n",
    "    fetch_url = r.url\n",
    "except Exception as _ex:\n",
    "    print(\"[verify] requests failed, falling back to urllib:\", _ex)\n",
    "    try:\n",
    "        from urllib import request as _urlreq, parse as _parse\n",
    "        fetch_url = f\"{base_url}?{_parse.urlencode(params)}\"\n",
    "        with _urlreq.urlopen(fetch_url, timeout=20) as resp:\n",
    "            img_bytes = resp.read()\n",
    "    except Exception as _ex2:\n",
    "        raise RuntimeError(f\"Static Maps fetch failed: {repr(_ex2)}\")\n",
    "\n",
    "# 4) Save to disk and show inline if possible\n",
    "out_dir = Path(\"output\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_path = out_dir / \"google_static_test.png\"\n",
    "with open(out_path, \"wb\") as f:\n",
    "    f.write(img_bytes)\n",
    "\n",
    "print(\"[verify] saved:\", str(out_path))\n",
    "print(\"[verify] url:\", fetch_url)\n",
    "\n",
    "# Try to display inline\n",
    "try:\n",
    "    import io\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    img = Image.open(io.BytesIO(img_bytes))\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "except Exception as _e:\n",
    "    print(\"[verify] inline display skipped:\", _e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781616d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panogeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
